

# Methods


To see how mining coverage has impacted rivers we need two datasets. First
we need to know when mining first occured on the landscape. Second we need
to know how these sections of mined lands are connected to river networks and
how mining impacts might propagate downstream. The first dataset is part of the
Pericack et al., paper (2018) labeled `First Mining Year (GeoTIFF)` in the 
figshare data repository. The second dataset we will create here using `whitebox` and elevation data from the region, but fist we need to download the data. 

```{r setup, include=FALSE}
library(sf) #Amazingly simple tidy GIS R package
library(mapview) #Interactive mapping of sf objects
library(tidyverse) #Good 'ol tidyverse (dplyr, readr, more)
library(elevatr) #R access to mapzen (dynamic downloading of DEMs)
library(raster) # Name says it all, rasters in R
library(whitebox) #amazing terrain analysis package
library(stars) # (spatiotemporal objects)
library(USAboundaries)
library(tmap) 
library(furrr) #Parallel mapping
library(animation)
library(terra) # much faster raster
library(nhdplusTools) #Navigate america's rivers
knitr::opts_chunk$set(echo = TRUE,eval = TRUE,
                      cache = TRUE, warning = FALSE,
                      message = FALSE)

par(mar = c(0,0,0,2))
# Run once!
#devtools::install_github("giswqs/whiteboxR")
```




## Data acquisition and organization


### Study Area

Let's grab a shapefile of the study area from Pericack et al., 2018. This will
be a zip of a shapefile, that we will need to unzip. 

```{r}

area_file <- 'data/in/study_area.zip'

if(!file.exists(area_file)){
download.file('https://ndownloader.figshare.com/articles/6253901?private_link=7a36745020ee5a517dcb',
              destfile=area_file,method='libcurl',mode='wb')

unzip(area_file, exdir = 'data/in/study_area')
}


```

### Watershed boundaries


Our study area is entirely within the 05 HUC 2 watershed basin from the USGS.
We can download these shapefiles directly from the USGS [here](https://catalog.data.gov/dataset/usgs-national-watershed-boundary-dataset-wbd-downloadable-data-collection-national-geospatial-) 


```{r}


wbd_file <- 'data/in/wbd_file.zip'

if(!file.exists(wbd_file)){
download.file('https://prd-tnm.s3.amazonaws.com/StagedProducts/Hydrography/WBD/HU2/Shape/WBD_05_HU2_Shape.zip',
              destfile = wbd_file, method = 'libcurl', mode = 'wb')

unzip(wbd_file, exdir = 'data/in/wbd')

}
```

Here we are simply downloading the Pericack et al First Mined dataset from
figshare using a Rmarkdown trick where we ask "does this file exist locally?"
If it does, then this code chunk will be skipped. If it doesn't then the 
data will be downloaded to your local directory under the folder 'data'. We
use these tricks throughout. 


### Flowlines

We will likely want to use our data with the National Hydrography Dataset,
so let's download some flowlines using Dave Blodgett's excellent `nhdplusTools`
package.

```{r}


huc4_list <- c('0510','0509','0507','0505','0513')



if(!file.exists('data/in/nhd/simple_lines.gpkg')){
  download_nhdplushr('data/in/nhd',huc4_list, download_files = T)
  
  d <- get_nhdplushr('data/in/nhd/05',
                     layers = 'NHDFlowline')$NHDFlowline
  
  #Get rid of small accumulated ares to make downstream calcs faster
  d1 <- d %>%
    filter(TotDASqKM >= 1) %>%
    st_transform(2163) %>%
    st_simplify(.,dTolerance = 500) 

  #Subset only large rivers for visualizing and testing burnout approach
  d3 <- d %>%
    dplyr::filter(TotDASqKM >= 200) %>%
    st_transform(2163) %>%
    st_simplify(.,dTolerance = 500) 

  
  st_write(d3,'data/in/nhd/simple_lines.gpkg',delete_dsn=T)
  st_write(d1,'data/in/nhd/lines_1km.gpkg',delete_dsn=T)
}



```




### Cumulative mining from Pericack et al., 2018

```{r download cume}


#Look for cumulative mining data
cume_file <- 'data/in/cume.tif'

#Check if the file already exists, if not run the commands below. 
cume_downloaded = !file.exists(cume_file)


if(cume_downloaded){
  #Create a data repo if one doesn't exist.
  dir.create('data')
  dir.create('data/in')
  dir.create('data/out')
  
  #Download data locally. Link is from paper
  download.file('https://ndownloader.figshare.com/files/11446991?private_link=e99954fc2876c6e96a7c',destfile=cume_file,method='libcurl',mode='wb')
  

}


```




### Download relevant elevation data

Our watershed analyses will be based on elevation data which we will 
get from elevatr which relies on mapzen elevation data. In the USA this 
data comes directly from USGS elevation data. 


```{r elev download}


raw_dem_file <- 'data/in/elev_raw.tif'
raw_dem_eval <- !file.exists(raw_dem_file)


if(raw_dem_eval){
  #Download data from elevatr (mapzen)
  cume_r <- raster('data/in/cume.tif')
  elev_raw <- get_elev_raster(cume_r,z=11)
  #Save raw file
  writeRaster(elev_raw,raw_dem_file,overwrite=T)
}
```


### Reproject elevation data into same projection as cumulative mining tif. 

The elevatr comes down in a different projection than the cumulative mining 
dataset, so we need to reproject it so that the cells match exactly in
resolution and location


```{r reproject}
proj_dem_file <- 'data/out/elev.tif'
reproject <- !file.exists(proj_dem_file)

if(reproject){
  elev_raw <- rast('data/in/elev_raw.tif')
  cume <- rast('data/in/cume.tif')
  #Project raster into cumulative raster cells and projection
  elev <- project(elev_raw,cume)
  #Save this elev data for whitebox
  terra::writeRaster(elev,proj_dem_file,overwrite=T)
}
```


## Data preparation

To prepare our data for whitebox terrain analyses, we need to process our
cumulative mining layer so that we produce 31 rasters that have cumulative mining
coverage up to that year. So we will make a tif called "1984.tif" and it will 
only contain mining up to 1984, and then 1985, '86 and so on. To demonstrate
this process we'll look at a county where there has been a lot of mining so we 
can see how cumulative mining changes over time, Boone County, WV.


### First Mining Year for Boone County


```{r first,fig.width= 7,fig.height= 7,fig.cap = 'First year of mountaintop mining in Boone County West Virginia', cache = F}

elev <- rast(proj_dem_file)

cume <- rast(cume_file)


boone <- us_counties(states='West Virginia') %>%
  filter(name == 'Boone') %>%
  #Match projections to mining data
  st_transform(crs(cume))

#Crop to boone
cume_boone <- crop(cume,boone) 
elev_boone <- crop(elev,boone)


#Terra doesn't work with tmap (yet presumably)
#So we have to use base!


#OMG HCL.colors is nice
plot(cume_boone,col=hcl.colors(30,'viridis'),frame=F,axes=F)
plot(elev_boone,col=hcl.colors(20,'Grays'),add=T,frame=F,axes=F, legend = F)
plot(cume_boone,col=hcl.colors(30,'viridis'),add=T, legend = F)



#First year of mining boone county
## Raster version of plotting
# tm_shape(elev_boone) + 
#   tm_raster(palette='Greys',
#             style='cont',
#             legend.show = F,
#             midpoint = 500) +  
# tm_shape(cume_boone) + 
#   tm_raster(title= '',
#             palette = 'viridis',
#             style= 'cont',
#             breaks=c(1984,1990,2000,2010,2015),
#             labels=c('pre-1985','1990','2000','2010','2015')) + 
#   tm_layout(legend.position = c(0.05,0.3),
#             legend.bg.color = 'white',
#             legend.text.size = 1.3) 


```

### Cumulative mining Boone County 1990

Just an example of how we are creating these rasters and what they will look 
like. 

```{r cume,fig.width = 7,fig.height = 7,fig.caption='Cumulative mining as of 1990'}
#Set all values above a year value to NA and all values before or equal to 1990 to 1

cut_year <- 1990 
rcl <- matrix(c(cut_year,2016,NA,
              1983,cut_year,1),nrow=2,ncol=3,byrow=T)


cume_cut <- classify(cume_boone,rcl)

plot(elev_boone,col=hcl.colors(20,'Grays'),frame=F,axes=F)
plot(cume_cut,col='red',add=T,useRaster=T, legend = F)

## Raster plotting with tmap (preferred but not available for faster terra)
#tm_shape(elev_boone) + 
#   tm_raster(palette='Greys',
#             style='cont',
#             legend.show = F,
#             midpoint = 500) +  
# tm_shape(cume_cut) + 
#   tm_raster(title='',
#             style='cat',
#             breaks=c(1),
#             labels=c(paste('Mined by end of',cut_year))) + 
#   tm_layout(legend.position = c(0.05,0.4),
#             legend.bg.color = 'white') 
# 
```

### Animated loop showing how this looks for all years


```{r boone gif, fig.height = 7,fig.width = 7,  fig.caption = 'Cumulative annual mining and last year mined',interval=0.2, animation.hook='gifski'}


cut_years = 1984:2015




for(i in cut_years){
  
  rcl <- matrix(c(i+1,2016,NA,
            1983,i,1),nrow=2,ncol=3,byrow=T)
  
  cume_cuts <- terra::classify(cume_boone,rcl)
  
  
  
terra::plot(elev_boone,col=hcl.colors(20,'Grays'),
       add=F,frame=F,axes=F,main=paste('Cumulative Mining Growth',i))
  terra::plot(cume_cuts,col='red',add=T,leg.shrink=.3,
              legend = F)


  # boone_map <- tm_shape(elev_boone) + 
  #   tm_raster(palette='Greys',
  #             style='cont',
  #             legend.show = F,
  #             midpoint = 500) +  
  #   tm_shape(cume_cut) + 
  #   tm_raster(title='',
  #             breaks = c(1984,1995,2005,2015),
  #             style='cont',
  #             palette = 'viridis') + 
  #   tm_layout(legend.position = c(0.05,0.3),
  #             legend.bg.color = 'white',
  #             legend.text.size = 1.4,
  #             legend.format=list(fun=function(x) formatC(x, digits=0, format="d")))
  # print(boone_map)
}


```



### Filtering and outputting cumulative mining rasters 1984-2015

```{r}

if(!dir.exists('data/out/annual_cumes')){
dir.create('data/out/annual_cumes')
}

#Years for cume data
years <- 1984:2015

year_files <- paste0('data/out/annual_cumes/',years,'.tif')

#Rerun? 
cumer_run <- !all(file.exists(year_files))


# Making a function for reclassifying Matrix for every year. 

mine_cumer <- function(year){
  library(terra)
  #Reclassify matrix
  rcl <- matrix(c(year+1,2016,NA,
              1983,year,1),nrow=2,ncol=3,byrow=T)
  
  #Reclassify raster
  cume_cut <- classify(cume,rcl)
  
  #write it out
  file = paste0('data/out/annual_cumes/',year,'.tif')
  terra::writeRaster(cume_cut,filename=file,overwrite=T)
}

#THis is why all the TERRA stuff is worth it about 100X faster than
#raster and 20X faster than using futures and furrr mapping
if(cumer_run){
map(years,mine_cumer)
}
```


### Picking "whole" flowlines for analysis

A critical aspect of figuring out the percent of mining in river networks is
understanding if our mining coverage dataset from [Pericack et al., 2015] covers
the entire watershed. Otherwise we could have a river (like the Ohio), which has
large portions that it drains from outside of the coverage of our data. 



```{r}

## Read in spatially simplified flowlines
simple_lines <- st_read('data/in/nhd/simple_lines.gpkg') 

## Read in almost complete flowline data
km1_lines <- st_read('data/in/nhd/lines_1km.gpkg')


#Get our study area and reproject
area <- st_read('data/in/study_area/Study-Area.shp') %>%
  st_transform(., st_crs(km1_lines)) 

#This creates a thin 2000m band around the study area (and outside of the study)
#Area by 50m. This skinny band will then be used to grab intersecting 
#flowlines which will tell us rivers that cross out of our study area boundary
area_zone <- area %>%
  #Bring the edge out 2000m
  st_buffer(2050) %>%
  #Cast the polygon as a line
  st_cast(.,'LINESTRING') %>%
  #Buffer the line by 2000m
  st_buffer(2000)


#Find lines that are outside our study area
out_lines <- km1_lines %>%
  group_by(LevelPathI) %>%
  filter(Pathlength == min(Pathlength)) %>%
  ungroup() %>%
  filter(st_intersects(., area_zone, sparse = F))


#Get COMIDs for the mainstems that fall outside our study area
mainstems_out <- out_lines$COMID
  


#Trace areas downstream of these comids
downstream_of_out <- function(comid,network = km1_lines){
  burn_out <- get_DM(comid,network = network)
}

#Run in parallel (slight speed improvements)
plan(multiprocess)
burn_outs <- future_map(mainstems_out,downstream_of_out)

#Unlist the map output
burn_out_vector <- unlist(burn_outs) %>% unique(.)


within_lines <- km1_lines %>%
  .[area,]

burns <- within_lines %>%
  filter(COMID %in% burn_out_vector2)


mapview(within_lines,color = 'blue') + 
  mapview(burns, color = 'red')
```


### Making an empty and a full dataset. 

The primary `whitebox` function we will be using to generate our cumulative 
mining maps will be

```{r}


```



## Using Whitebox to get Annual Cumulative Mining in river networks


```{r}

```

